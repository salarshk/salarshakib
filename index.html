<!DOCTYPE html>
<html>
<head>
    <title>Welcome to My Personal Website</title>
</head>
<body>
    <h1>Hello, I'm Salar!</h1>
    <p>Welcome to my personal website hosted on GitHub Pages.</p>
</body>
</html>

<section id="news">
    <h2>News</h2>
    <ul>
        <li><strong>July 2024:</strong> Stable Diffusion 3 won the Best Paper Award at ICML 2024 (0.3%).</li>
        <li><strong>May 2024:</strong> Check out our new pre-print on Stable Diffusion 3. Also accepted at ICML 2024.</li>
        <li><strong>July 2023:</strong> I earned my PhD with distinction. My thesis and presentation are available online.</li>
        <li><strong>May 2023:</strong> I joined Stability as a research scientist.</li>
        <li><strong>March 2023:</strong> Check out our new pre-print on "The Role of Pre-training Data in Transfer Learning." A shorter version is accepted at the ICLR Workshop on Multimodal Representation Learning.</li>
        <li><strong>January 2023:</strong> Our REPAIR paper is accepted at ICLR 2023. This follows up on our work on permutation invariance of neural networks.</li>
        <li><strong>January 2023:</strong> As part of my internship at UW, we introduced DataComp, a new large-scale multimodal benchmark to measure the effect of data curation strategies on downstream model performance. Stay tuned!</li>
        <li><strong>January 2023:</strong> I am invited to give a talk about our recent work on permutation invariances at the MIT-IBM Watson AI Lab, IBM Research on February 2nd. Drop me an email if you'd like to attend!</li>
        <li><strong>August 2022:</strong> One paper is accepted at MICCAI 2022 Applications of Medical AI (AMAI) Workshop.</li>
        <li><strong>June 2022:</strong> Two papers are accepted at ICML 2022 Hardware Aware Efficient Training and Pre-training: Perspectives, Pitfalls, and Paths Forward workshops.</li>
        <li><strong>June 2022:</strong> I organized the 2nd Efficient Machine Learning Workshop, this time in Vienna.</li>
        <li><strong>February 2022:</strong> I will give a talk about our recent work on Permutation Invariance at the EPFL Virtual Symposium: Loss Landscape of Neural Networks.</li>
        <li><strong>January 2022:</strong> One paper is accepted at ICLR 2022 (score: 7.0, top 5%).</li>
    </ul>
</section>
